{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## CNN Training\n",
    "\n",
    "Train a CNN network to extract the needle position of an analog pointer\n",
    "\n",
    "**ONLY FOR TESTING PURPOSE: Runs only a few epochs to mainly test github training environment and actions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Parameter\n",
    "\n",
    "Note: Do not rename any of the variables in this section, because the they are externally used in github action `Train Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Model naming\n",
    "TFlite_MainType: str = 'ana-cont'\n",
    "TFlite_Version: str  = 'undefined'\n",
    "TFlite_Size: str     = 's3'\n",
    "\n",
    "# Validation size\n",
    "# Note: 0.0 = 0% validation size, use all images for training\n",
    "Validation_Percentage = 0.2\n",
    "\n",
    "# Folders\n",
    "Input_Dir: str  = 'data_resize_all'\n",
    "Output_Dir: str = 'models/ana-cont'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libaries and defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from PIL import Image \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.plot_functions import plot_dataset, plot_dataset_analog\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "# Make sure version is 4 characters long if version is defined as int (e.g. papermill paramter 100 -> 0100)\n",
    "if isinstance(TFlite_Version, int):\n",
    "    TFlite_Version = str(TFlite_Version).zfill(4)\n",
    "\n",
    "\n",
    "# Prepare folders\n",
    "if not (Path(Input_Dir).exists() and Path(Input_Dir).is_dir()): # Check if input is availabe\n",
    "    sys.exit(f\"Aborting: Folder '{Input_Dir}' does not exist.\")\n",
    "    \n",
    "Path(Output_Dir).mkdir(parents=True, exist_ok=True)  # Create output folder if it doesn't exist\n",
    "\n",
    "\n",
    "# Disable GPUs\n",
    "try:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Picture size must be 32x32 with 3 color channels (RGB)\n",
    "* The filename contains the informations needed for training in the first 3 digits::\n",
    "* Typical filename: \n",
    "    * x.y-zzzz.jpg \n",
    "    * e.g. \"4.6_Lfd-1406_zeiger3_2019-06-02T050011.jpg\"\n",
    "\n",
    "|Place holder | Meaning                     | Usage             |\n",
    "|-------------|-----------------------------|-------------------|\n",
    "| **x.y**     | readout value               | **to be learned** |\n",
    "| zzzz        | additional information      | not needed        |\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected output for each image in the corresponding y_data[]\n",
    "    * The periodic nature is reflected in a **sin/cos coding**, which allows to restore the angle/counter value with an arctan later on.\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) as the filenames are on order due to the encoding of the expected analog readout in the filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f\"{Input_Dir}/*.jpg\")\n",
    "num_files = len(files)\n",
    "\n",
    "x_data = np.zeros((num_files, 32, 32, 3), dtype=\"float32\")\n",
    "y_data = np.zeros((num_files, 2), dtype=\"float32\")\n",
    "\n",
    "for idx, aktfile in enumerate(files):\n",
    "    test_image = Image.open(aktfile)\n",
    "    #test_image = np.array(test_image.resize((32, 32), Image.LANCZOS), dtype=\"float32\")  # Resize while loading\n",
    "    test_image = np.array(test_image, dtype=\"float32\")  # No resizing\n",
    "    base = Path(aktfile).name\n",
    "    target_number = float(base[:3]) / 10\n",
    "    target_sin = math.sin(target_number * math.pi * 2)\n",
    "    target_cos = math.cos(target_number * math.pi * 2)\n",
    "\n",
    "    # Store image and target values\n",
    "    x_data[idx] = test_image\n",
    "    y_data[idx] = [target_sin, target_cos]\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if Validation_Percentage > 0:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Validation_Percentage)\n",
    "else:\n",
    "    x_train = x_data\n",
    "    y_train = y_data\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "##### Important\n",
    "* Shape of the input layer: (32, 32, 3)\n",
    "* Shape of the output layer: (2) - sin and cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = BatchNormalization()(input)\n",
    "x = Conv2D(16, (3, 3), padding='same', activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(32, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
    "\n",
    "output = Dense(2)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    metrics=[\"mse\"]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 8\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.2\n",
    "Zoom_Range = 0.05\n",
    "\n",
    "def random_invert_image(x, probability_invert=0.2):\n",
    "    \"\"\"\n",
    "    Invert an image with a given probability\n",
    "    \"\"\"\n",
    "    if random.random() > probability_invert:\n",
    "        return x\n",
    "    return 255 - x  # Invert image\n",
    "\n",
    "\n",
    "def random_white_balance(x, strength_range=(0.9, 1.1)):\n",
    "    \"\"\"\n",
    "    Simulates poor white balance by randomly scaling RGB channels independently.\n",
    "    strength_range controls how strong the color cast distortion is.\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    # Random scaling for each channel (simulates color cast)\n",
    "    r_scale = np.random.uniform(*strength_range)\n",
    "    g_scale = np.random.uniform(*strength_range)\n",
    "    b_scale = np.random.uniform(*strength_range)\n",
    "\n",
    "    x[..., 0] *= r_scale  # Red channel\n",
    "    x[..., 1] *= g_scale  # Green channel\n",
    "    x[..., 2] *= b_scale  # Blue channel\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocessing(x):\n",
    "    x = random_invert_image(x)\n",
    "    x = random_white_balance(x)\n",
    "    x = np.clip(x, 0.0, 255.0)\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "\n",
    "# Training data\n",
    "print(\"Training data\")\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range, Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range, Shift_Range],\n",
    "                             brightness_range=[1 - Brightness_Range, 1 + Brightness_Range],\n",
    "                             zoom_range=[1 - Zoom_Range, 1 + Zoom_Range],\n",
    "                             channel_shift_range=5,\n",
    "                             shear_range=1,\n",
    "                             preprocessing_function=preprocessing\n",
    "                            )\n",
    "\n",
    "train_iterator = datagen.flow(x_train, y_train, batch_size=Batch_Size)\n",
    "plot_dataset_analog(train_iterator)     \n",
    "\n",
    "if (Validation_Percentage > 0):\n",
    "    # Validation data\n",
    "    datagen_val = ImageDataGenerator() # No augmentation for validation\n",
    "    validation_iterator = datagen_val.flow(x_test, y_test, batch_size=Batch_Size)\n",
    "    print(\"  \")\n",
    "    print(\"Validation data\")\n",
    "    plot_dataset_analog(validation_iterator, rows=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Epoch_Anz = 5\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=5, min_lr=1e-5\n",
    ")\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', mode='min', patience=25, restore_best_weights=True\n",
    ")\n",
    "\n",
    "if (Validation_Percentage > 0):\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz, callbacks=[lr_scheduler, early_stopping], verbose=0)\n",
    "else:\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz, callbacks=[lr_scheduler, early_stopping], verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Validation_Percentage > 0):\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training','validation'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model verification\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* Images, that have a bigger deviation as the parameter \"deviation_max_list\" are printed in a list to check the picture and labeling itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(Input_Dir + '/*.*')\n",
    "res = []\n",
    "i = 0\n",
    "deviation_max_list = 0.11\n",
    "\n",
    "for aktfile in sorted(files):\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = (float(base[0:3])) / 10\n",
    "    \n",
    "    target_sin = math.sin(target * math.pi * 2)\n",
    "    target_cos = math.cos(target * math.pi * 2)\n",
    "\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,32,3])\n",
    "    classes = model.predict(img, verbose=0)\n",
    "    \n",
    "    out_sin = classes[0][0]  \n",
    "    out_cos = classes[0][1]\n",
    "    out_target = (np.arctan2(out_sin, out_cos)/(2*math.pi)) % 1\n",
    "\n",
    "    dev_target = target - out_target\n",
    "    \n",
    "    if abs(dev_target + 1) < abs(dev_target):\n",
    "        out_target = out_target - 1\n",
    "        dev_target = target - out_target\n",
    "    else:\n",
    "        if abs(dev_target - 1) < abs(dev_target):\n",
    "            out_target = out_target + 1\n",
    "            dev_target = target - out_target\n",
    "               \n",
    "    if abs(dev_target) > deviation_max_list:\n",
    "        log_devition = aktfile + \" \" + str(target) + \" \" + str(out_target) +  \" \" + str(dev_target)\n",
    "        print(log_devition)\n",
    "\n",
    "        # Save to file\n",
    "        with open(f\"{Output_Dir}/false_predictions.txt\", \"a\") as f:  # 'a' to append\n",
    "            f.write(log_devition + \"\\n\")\n",
    "    \n",
    "    res.append(np.array([target, out_target, dev_target, out_sin, out_cos, i]))\n",
    "\n",
    "res = np.asarray(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result: Value')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Real', 'Prediction'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,2])\n",
    "plt.title('Result: Value Deviation (Prediction)')\n",
    "plt.ylabel('Value Deviation')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Deviation'], loc='upper left')\n",
    "#plt.ylim(-0.3, 0.3)\n",
    "plt.show()\n",
    "\n",
    "statistic = np.array([np.mean(res[:,2]), np.std(res[:,2]), np.min(res[:,2]), np.max(res[:,2])])\n",
    "print(statistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,3])\n",
    "plt.plot(res[:,4])\n",
    "plt.title('Result: Sin/Cos Mapping')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['sin', 'cos'], loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = f\"{Output_Dir}/{TFlite_MainType}_{TFlite_Version}_{TFlite_Size}.tflite\"\n",
    "\n",
    "# TensorFlow Lite conversion\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open(FileName, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model saved successfully. File: {FileName}\")\n",
    "print(f\"File size: {Path(FileName).stat().st_size} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = f\"{Output_Dir}/{TFlite_MainType}_{TFlite_Version}_{TFlite_Size}_q.tflite\"\n",
    "\n",
    "# Representative dataset function\n",
    "def representative_dataset():\n",
    "    for n in range(x_data[0].shape[0]):\n",
    "        data = np.expand_dims(x_data[n], axis=0)\n",
    "        yield [data.astype(np.float32)]\n",
    "\n",
    "# TensorFlow Lite conversion with optimizations\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter._experimental_disable_per_channel_quantization_for_dense_layers = True\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Save the converted model to the specified file\n",
    "with open(FileName, \"wb\") as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print(f\"Model saved successfully. File: {FileName}\")\n",
    "print(f\"File size: {Path(FileName).stat().st_size} bytes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflite2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
